{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "\n",
    "\n",
    "import os\n",
    "import zipfile\n",
    "from PIL import Image\n",
    "import time\n",
    "from torch.optim import optimizer\n",
    "from torchsummary import summary\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.cuda.amp import grad_scaler, autocast_mode\n",
    "\n",
    "\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "torch.manual_seed(1211)\n",
    "\n",
    "# data_zip_dir = '/opt/ml/skku/dog_classifier'\n",
    "# train_zip_dir = os.path.join(data_zip_dir, 'train.zip')\n",
    "# test_zip_dir = os.path.join(data_zip_dir, 'test.zip')\n",
    "\n",
    "# with zipfile.ZipFile(train_zip_dir, 'r') as z:\n",
    "#     z.extractall()\n",
    "# with zipfile.ZipFile(test_zip_dir, 'r') as z:\n",
    "#     z.extractall()\n",
    "\n",
    "# train_dir = os.path.join('/opt/ml/skku/dog_classifier', 'train')\n",
    "# test_dir = os.path.join('/opt/ml/skku/dog_classifier', 'test')\n",
    "\n",
    "\n",
    "\n",
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, files, root, transform):\n",
    "        self.files = files\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "\n",
    "        if 'cat' in files[0]:\n",
    "            self.label = 0\n",
    "        else:\n",
    "            self.label = 1\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(os.path.join(self.root, self.files[index]))\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, self.label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, files, root, transform):\n",
    "        self.files = files\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(os.path.join(self.root, self.files[index]))\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "\n",
    "# # Depthwise Separable Convolution\n",
    "# class SeparableConv(nn.Module):\n",
    "#     def __init__(self, in_channels, out_channels):\n",
    "#         super().__init__()\n",
    "\n",
    "#         self.seperable = nn.Sequential(\n",
    "#             nn.Conv2d(in_channels, in_channels, 3, stride=1, padding=1, bias=False),\n",
    "#             nn.Conv2d(in_channels, out_channels, 1, stride=1, padding=0, bias=False)\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.seperable(x)\n",
    "#         return x\n",
    "\n",
    "# # EnrtyFlow\n",
    "# class EntryFlow(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "\n",
    "#         self.conv1 = nn.Sequential(\n",
    "#             nn.Conv2d(3, 32, 3, stride=2, padding=1, bias=False),\n",
    "#             nn.BatchNorm2d(32),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Conv2d(32, 64, 3, stride=1, padding=0, bias=False),\n",
    "#             nn.BatchNorm2d(64),\n",
    "#             nn.ReLU()\n",
    "#         )\n",
    "\n",
    "#         self.conv2_residual = nn.Sequential(\n",
    "#             SeparableConv(64, 128),\n",
    "#             nn.BatchNorm2d(128),\n",
    "#             nn.ReLU(),\n",
    "#             SeparableConv(128, 128),\n",
    "#             nn.BatchNorm2d(128),\n",
    "#             nn.MaxPool2d(3, stride=2, padding=1)\n",
    "#         )\n",
    "\n",
    "#         self.conv2_shortcut = nn.Sequential(\n",
    "#             nn.Conv2d(64, 128, 1, stride=2, padding=0),\n",
    "#             nn.BatchNorm2d(128)\n",
    "#         )\n",
    "\n",
    "#         self.conv3_residual = nn.Sequential(\n",
    "#             nn.ReLU(),\n",
    "#             SeparableConv(128, 256),\n",
    "#             nn.BatchNorm2d(256),\n",
    "#             nn.ReLU(),\n",
    "#             SeparableConv(256, 256),\n",
    "#             nn.BatchNorm2d(256),\n",
    "#             nn.MaxPool2d(3, stride=2, padding=1)\n",
    "#         )\n",
    "\n",
    "#         self.conv3_shortcut = nn.Sequential(\n",
    "#             nn.Conv2d(128, 256, 1, stride=2, padding=0),\n",
    "#             nn.BatchNorm2d(256)\n",
    "#         )\n",
    "\n",
    "#         self.conv4_residual = nn.Sequential(\n",
    "#             nn.ReLU(),\n",
    "#             SeparableConv(256, 728),\n",
    "#             nn.BatchNorm2d(728),\n",
    "#             nn.ReLU(),\n",
    "#             SeparableConv(728, 728),\n",
    "#             nn.BatchNorm2d(728),\n",
    "#             nn.MaxPool2d(3, stride=2, padding=1)\n",
    "#         )\n",
    "\n",
    "#         self.conv4_shortcut = nn.Sequential(\n",
    "#             nn.Conv2d(256, 728, 1, stride=2, padding=0),\n",
    "#             nn.BatchNorm2d(728)\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.conv1(x)\n",
    "#         x = self.conv2_residual(x) + self.conv2_shortcut(x)\n",
    "#         x = self.conv3_residual(x) + self.conv3_shortcut(x)\n",
    "#         x = self.conv4_residual(x) + self.conv4_shortcut(x)\n",
    "#         return x\n",
    "\n",
    "\n",
    "# # MiddleFlow\n",
    "# class MiddleFlow(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "\n",
    "#         self.conv_residual = nn.Sequential(\n",
    "#             nn.ReLU(),\n",
    "#             SeparableConv(728, 728),\n",
    "#             nn.BatchNorm2d(728),\n",
    "#             nn.ReLU(),\n",
    "#             SeparableConv(728, 728),\n",
    "#             nn.BatchNorm2d(728),\n",
    "#             nn.ReLU(),\n",
    "#             SeparableConv(728, 728),\n",
    "#             nn.BatchNorm2d(728)\n",
    "#         )\n",
    "\n",
    "#         self.conv_shortcut = nn.Sequential()\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         return self.conv_shortcut(x) + self.conv_residual(x)\n",
    "\n",
    "\n",
    "# # ExitFlow\n",
    "# class ExitFlow(nn.Module):\n",
    "#     def __init__(self, num_classes=10):\n",
    "#         super().__init__()\n",
    "\n",
    "#         self.conv1_residual = nn.Sequential(\n",
    "#             nn.ReLU(),\n",
    "#             SeparableConv(728, 1024),\n",
    "#             nn.BatchNorm2d(1024),\n",
    "#             nn.ReLU(),\n",
    "#             SeparableConv(1024, 1024),\n",
    "#             nn.BatchNorm2d(1024),\n",
    "#             nn.MaxPool2d(3, stride=2, padding=1)\n",
    "#         )\n",
    "\n",
    "#         self.conv1_shortcut = nn.Sequential(\n",
    "#             nn.Conv2d(728, 1024, 1, stride=2, padding=0),\n",
    "#             nn.BatchNorm2d(1024)\n",
    "#         )\n",
    "\n",
    "#         self.conv2 = nn.Sequential(\n",
    "#             SeparableConv(1024, 1536),\n",
    "#             nn.BatchNorm2d(1536),\n",
    "#             nn.ReLU(),\n",
    "#             SeparableConv(1536, 2048),\n",
    "#             nn.BatchNorm2d(2048),\n",
    "#             nn.ReLU()\n",
    "#         )\n",
    "\n",
    "#         self.avg_pool = nn.AdaptiveAvgPool2d((1,1))\n",
    "    \n",
    "#     def forward(self, x):\n",
    "#         x = self.conv1_residual(x) + self.conv1_shortcut(x)\n",
    "#         x = self.conv2(x)\n",
    "#         x = self.avg_pool(x)\n",
    "#         return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Xception\n",
    "# class Xception(nn.Module):\n",
    "#     def __init__(self, num_classes=2, init_weights=True):\n",
    "#         super().__init__()\n",
    "#         self.init_weights = init_weights\n",
    "\n",
    "#         self.entry = EntryFlow()\n",
    "#         self.middle = self._make_middle_flow()\n",
    "#         self.exit = ExitFlow()\n",
    "\n",
    "#         self.linear = nn.Linear(2048, num_classes)\n",
    "\n",
    "#         def init_weight(m):\n",
    "#             if isinstance(m, nn.Conv2d):\n",
    "#                 torch.nn.init.xavier_uniform(m.weight)\n",
    "                \n",
    "\n",
    "#         # weights initialization\n",
    "#         if self.init_weights:\n",
    "#             self.entry.conv1.apply(init_weight)\n",
    "        \n",
    "        \n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.entry(x)\n",
    "#         x = self.middle(x)\n",
    "#         x = self.exit(x)\n",
    "#         x = x.view(x.size(0), -1)\n",
    "#         x = self.linear(x)\n",
    "#         return x\n",
    "\n",
    "#     def _make_middle_flow(self):\n",
    "#         middle = nn.Sequential()\n",
    "#         for i in range(8):\n",
    "#             middle.add_module('middle_block_{}'.format(i), MiddleFlow())\n",
    "#         return middle\n",
    "\n",
    "#     def _initialize_weights(self):\n",
    "#         for m in self.modules():\n",
    "#             if isinstance(m, nn.Conv2d):\n",
    "#                 nn.init_kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "#                 if m.bias is not None:\n",
    "#                     nn.init_constant_(m.bias, 0)\n",
    "#             elif isinstance(m, nn.BatchNorm2d):\n",
    "#                 nn.init_constant_(m.weight, 1)\n",
    "#                 nn.init_bias_(m.bias, 0)\n",
    "#             elif isinstance(m, nn.Linear):\n",
    "#                 nn.init_normal_(m.weight, 0, 0.01)\n",
    "#                 nn.init_constant_(m.bias, 0)\n",
    "\n",
    "# # check model\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# x = torch.randn(3, 3, 299, 299).to(device)\n",
    "# model = Xception().to(device)\n",
    "# output = model(x)\n",
    "# print('output size:', output.size())\n",
    "\n",
    "# # print summary\n",
    "# summary(model, (3, 299, 299), device=device.type)\n",
    "\n",
    "import timm\n",
    "from tqdm import tqdm\n",
    "###########\n",
    "\n",
    "\n",
    "def rand_bbox(size, lam):\n",
    "    H = size[2]\n",
    "    W = size[3]\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = int(W * cut_rat)\n",
    "    cut_h = int(H * cut_rat)\n",
    "\n",
    "\n",
    "    cx = np.random.randn() + W//2\n",
    "    cy = np.random.randn() + H//2\n",
    "\n",
    "    # 패치의 4점\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W//2)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W//2)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "\n",
    "    return int(bbx1), int(bby1), int(bbx2), int(bby2)\n",
    "\n",
    "\n",
    "if __name__=='__main__':\n",
    "\n",
    "    k_folds = 5\n",
    "    num_epochs = 50\n",
    "    \n",
    "\n",
    "    # For fold results\n",
    "    results = {}\n",
    "\n",
    "    # Set fixed random number seed\n",
    "\n",
    "\n",
    "    dog_files = [f'dog.{i}.jpg' for i in range(12500)]\n",
    "    cat_files = [f'cat.{i}.jpg' for i in range(12500)]\n",
    "    test_files = [f'{i}.jpg' for i in range(1,12500)]\n",
    "    \n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.Resize((299,299)),\n",
    "        transforms.RandomAffine(degrees=20, translate=None, scale=None, shear=None, resample=False, fillcolor=0),\n",
    "        transforms.RandomCrop(255),\n",
    "        transforms.RandomHorizontalFlip(0.5),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
    "    ])\n",
    "\n",
    "    test_transform = transforms.Compose([\n",
    "        transforms.Resize((299,299)),\n",
    "        transforms.RandomHorizontalFlip(0.5),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
    "    ])\n",
    "\n",
    "\n",
    "    kfold = StratifiedKFold(n_splits=k_folds, shuffle=True)\n",
    "\n",
    "    # Start print\n",
    "    print('--------------------------------')\n",
    "\n",
    "    train_dog_dataset = TrainDataset(dog_files, '/opt/ml/train', train_transform)\n",
    "    train_cat_dataset = TrainDataset(cat_files, '/opt/ml/train', train_transform)\n",
    "    # test_dataset = TestDataset(test_files, '/opt/ml/test1', test_transform)\n",
    "\n",
    "    train_dataset = ConcatDataset([train_dog_dataset, train_cat_dataset])\n",
    "    target_dog = torch.ones(len(dog_files))\n",
    "    target_cat = torch.zeros(len(cat_files))\n",
    "    target = torch.cat([target_dog,target_cat])\n",
    "    \n",
    "    \n",
    "\n",
    "    for fold, (train_ids, val_ids) in enumerate(kfold.split(train_dataset,target)):\n",
    "        torch.cuda.empty_cache()\n",
    "        model = timm.create_model('xception', pretrained=True, num_classes=2).to(device)\n",
    "        # model = timm.create_model('xception', pretrained=True, num_classes=2)\n",
    "        # model.to(device)\n",
    "\n",
    "        print(train_ids, val_ids)\n",
    "        print(f'FOLD {fold}')\n",
    "        print('-----------------------------------')\n",
    "\n",
    "        train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
    "        val_subsampler = torch.utils.data.SubsetRandomSampler(val_ids)\n",
    "\n",
    "\n",
    "        train_loader = DataLoader(train_dataset, batch_size=192, sampler=train_subsampler, drop_last=True)\n",
    "        val_loader = DataLoader(train_dataset, batch_size=192, sampler=val_subsampler, drop_last=True)\n",
    "        # test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "        criterion = nn.CrossEntropyLoss(reduction='sum')\n",
    "        opt = optim.Adam(model.parameters(), lr=0.0002)\n",
    "\n",
    "        scaler = grad_scaler.GradScaler()\n",
    "\n",
    "\n",
    "        for epoch in range(5):\n",
    "            print(f'=====EPOCH : {epoch}=====')\n",
    "            model.train()\n",
    "            train_loss = 0\n",
    "            train_acc = 0\n",
    "            val_loss =0\n",
    "            val_acc =0\n",
    "            epoch_loss = 0\n",
    "            epoch_acc = 0\n",
    "            epoch_val_loss = 0\n",
    "            epoch_val_acc = 0\n",
    "            \n",
    "\n",
    "            for i, data in enumerate(tqdm(train_loader)):\n",
    "                inputs, targets = data\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "                opt.zero_grad()\n",
    "                with autocast_mode.autocast():\n",
    "\n",
    "                    if np.random.random() > 0.5: # Cutmix\n",
    "                        random_index = torch.randperm(inputs.size()[0])\n",
    "                        target_a = targets\n",
    "                        targeb_b = targets[random_index]\n",
    "\n",
    "                        lam = np.random.beta(1.0, 1.0)\n",
    "                        bbx1, bby1, bbx2, bby2 = rand_bbox(inputs.size(), lam)\n",
    "\n",
    "                        inputs[:, :, bbx1:bbx2, bby1:bby2] = inputs[random_index, :, bbx1:bbx2, bby1:bby2]\n",
    "                        lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (inputs.size()[-1] * inputs.size()[-2]))\n",
    "\n",
    "                        pred = model(inputs.float())\n",
    "                        loss = criterion(pred, target_a) * lam + criterion(pred, targeb_b) * (1. - lam)\n",
    "\n",
    "                        _, preds = torch.max(pred, 1)\n",
    "                        scaler.scale(loss).backward()\n",
    "                        scaler.step(opt)\n",
    "                        scaler.update()\n",
    "\n",
    "                    else:\n",
    "                        pred = model(inputs)\n",
    "                        loss = criterion(pred, targets)\n",
    "\n",
    "                        _,preds = torch.max(pred, 1)\n",
    "\n",
    "                        scaler.scale(loss).backward()\n",
    "                        scaler.step(opt)\n",
    "                        scaler.update()\n",
    "                \n",
    "\n",
    "                    train_loss += loss.item()\n",
    "                    train_acc += torch.sum(preds == targets.data)\n",
    "            epoch_loss = train_loss / len(train_loader.dataset)\n",
    "            epoch_acc = train_acc / len(train_loader.dataset)\n",
    "            print(epoch_loss)\n",
    "            print(epoch_acc)\n",
    "\n",
    "        # Iterate over the test data and generate predictions\n",
    "            with torch.no_grad():\n",
    "                # Iterate over the test data and generate predictions\n",
    "                for i, data in enumerate(val_loader, 0):\n",
    "                    model.eval()\n",
    "                    inputs, targets = data\n",
    "                    inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "\n",
    "                    pred = model(inputs)\n",
    "                    loss = criterion(pred, targets)\n",
    "                    # Set total and correct\n",
    "                    _, preds= torch.max(pred, 1)\n",
    "                    val_loss += loss.item()\n",
    "                    val_acc += torch.sum(preds == targets.data)\n",
    "                epoch_val_loss = val_loss / len(val_loader.dataset)\n",
    "                epoch_val_acc = val_acc / len(val_loader.dataset)\n",
    "                print(epoch_val_loss)\n",
    "                print(epoch_val_acc)\n",
    "                # Print accuracy\n",
    "            print('Accuracy for fold %d: %d %%' % (fold, 100.0 * epoch_val_acc))\n",
    "            print('--------------------------------')\n",
    "            results[fold] = 100.0 * (epoch_val_acc)\n",
    "\n",
    "\n",
    "\n",
    "        # Print fold results\n",
    "        print(f'K-FOLD CROSS VALIDATION RESULTS FOR {k_folds} FOLDS')\n",
    "        print('--------------------------------')\n",
    "        sums = 0.0\n",
    "        for key, value in results.items():\n",
    "            print(f'Fold {key}: {value} %')\n",
    "            sums += value\n",
    "        print(f'Average: {sums/len(results.items())} %')\n",
    "        torch.save(model.state_dict(), f'/opt/ml/skku/dog_classifier/{k_folds}_Xception.pt')\n",
    "\n",
    "\n",
    "\n",
    "    # samples, labels = iter(train_loader).next()\n",
    "\n",
    "    # classes = {0:'cat', 1:'dog'}\n",
    "    # fig = plt.figure(figsize=(10,10))\n",
    "    # for i in range(25):\n",
    "    #     a = fig.add_subplot(5, 5, i+1)\n",
    "    #     a.set_title(classes[labels[i].item()])\n",
    "    #     a.axis('off')\n",
    "    #     a.imshow(np.transpose(samples[i].numpy(), (1,2,0)))\n",
    "    # plt.subplots_adjust(bottom=0.2, top=0.6, hspace=0)\n",
    "\n",
    "\n",
    "\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--------------------------------\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 0/104 [00:00<?, ?it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[    0     1     2 ... 24997 24998 24999] [    3    13    14 ... 24987 24989 24994]\n",
      "FOLD 0\n",
      "-----------------------------------\n",
      "=====EPOCH : 0=====\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 104/104 [03:57<00:00,  2.29s/it]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.21458009516716003\n",
      "tensor(0.7250, device='cuda:0')\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 0/104 [00:00<?, ?it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.011081035175323486\n",
      "tensor(0.1982, device='cuda:0')\n",
      "Accuracy for fold 0: 19 %\n",
      "--------------------------------\n",
      "=====EPOCH : 1=====\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 104/104 [03:57<00:00,  2.29s/it]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.13855539295196534\n",
      "tensor(0.7686, device='cuda:0')\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 0/104 [00:00<?, ?it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.00706688494682312\n",
      "tensor(0.1983, device='cuda:0')\n",
      "Accuracy for fold 0: 19 %\n",
      "--------------------------------\n",
      "=====EPOCH : 2=====\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 104/104 [04:00<00:00,  2.31s/it]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.13339429691791535\n",
      "tensor(0.7713, device='cuda:0')\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 0/104 [00:00<?, ?it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.005189665851593018\n",
      "tensor(0.1982, device='cuda:0')\n",
      "Accuracy for fold 0: 19 %\n",
      "--------------------------------\n",
      "=====EPOCH : 3=====\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 104/104 [03:57<00:00,  2.28s/it]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.12834641173243522\n",
      "tensor(0.7736, device='cuda:0')\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 0/104 [00:00<?, ?it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.004917795104980469\n",
      "tensor(0.1984, device='cuda:0')\n",
      "Accuracy for fold 0: 19 %\n",
      "--------------------------------\n",
      "=====EPOCH : 4=====\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 104/104 [03:58<00:00,  2.29s/it]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.12028498272061348\n",
      "tensor(0.7716, device='cuda:0')\n",
      "0.005472447624206543\n",
      "tensor(0.1983, device='cuda:0')\n",
      "Accuracy for fold 0: 19 %\n",
      "--------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n",
      "--------------------------------\n",
      "Fold 0: 19.827999114990234 %\n",
      "Average: 19.827999114990234 %\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 0/104 [00:00<?, ?it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[    0     2     3 ... 24997 24998 24999] [    1     4     5 ... 24970 24971 24986]\n",
      "FOLD 1\n",
      "-----------------------------------\n",
      "=====EPOCH : 0=====\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 104/104 [03:56<00:00,  2.28s/it]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.21679947229385377\n",
      "tensor(0.7322, device='cuda:0')\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 0/104 [00:00<?, ?it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.010970230617523193\n",
      "tensor(0.1983, device='cuda:0')\n",
      "Accuracy for fold 1: 19 %\n",
      "--------------------------------\n",
      "=====EPOCH : 1=====\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 104/104 [03:57<00:00,  2.28s/it]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.1483255226278305\n",
      "tensor(0.7630, device='cuda:0')\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 0/104 [00:00<?, ?it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.006378384094238281\n",
      "tensor(0.1986, device='cuda:0')\n",
      "Accuracy for fold 1: 19 %\n",
      "--------------------------------\n",
      "=====EPOCH : 2=====\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 104/104 [03:58<00:00,  2.30s/it]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.1324738039422035\n",
      "tensor(0.7720, device='cuda:0')\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 0/104 [00:00<?, ?it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.007541522197723389\n",
      "tensor(0.1982, device='cuda:0')\n",
      "Accuracy for fold 1: 19 %\n",
      "--------------------------------\n",
      "=====EPOCH : 3=====\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 104/104 [03:58<00:00,  2.30s/it]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.1481166330242157\n",
      "tensor(0.7681, device='cuda:0')\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 0/104 [00:00<?, ?it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.0058887298202514645\n",
      "tensor(0.1983, device='cuda:0')\n",
      "Accuracy for fold 1: 19 %\n",
      "--------------------------------\n",
      "=====EPOCH : 4=====\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 104/104 [03:59<00:00,  2.31s/it]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.12879239689528943\n",
      "tensor(0.7746, device='cuda:0')\n",
      "0.005647083339691162\n",
      "tensor(0.1980, device='cuda:0')\n",
      "Accuracy for fold 1: 19 %\n",
      "--------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n",
      "--------------------------------\n",
      "Fold 0: 19.827999114990234 %\n",
      "Fold 1: 19.803998947143555 %\n",
      "Average: 19.815998077392578 %\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 0/104 [00:00<?, ?it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[    0     1     3 ... 24993 24994 24997] [    2     8    11 ... 24996 24998 24999]\n",
      "FOLD 2\n",
      "-----------------------------------\n",
      "=====EPOCH : 0=====\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 104/104 [03:59<00:00,  2.31s/it]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.2081415474128723\n",
      "tensor(0.7286, device='cuda:0')\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 0/104 [00:00<?, ?it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.0062109381484985356\n",
      "tensor(0.1982, device='cuda:0')\n",
      "Accuracy for fold 2: 19 %\n",
      "--------------------------------\n",
      "=====EPOCH : 1=====\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 104/104 [03:58<00:00,  2.30s/it]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.16021873863697053\n",
      "tensor(0.7628, device='cuda:0')\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 0/104 [00:00<?, ?it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.007725379638671875\n",
      "tensor(0.1982, device='cuda:0')\n",
      "Accuracy for fold 2: 19 %\n",
      "--------------------------------\n",
      "=====EPOCH : 2=====\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 104/104 [03:58<00:00,  2.30s/it]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.13221036530971528\n",
      "tensor(0.7654, device='cuda:0')\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 0/104 [00:00<?, ?it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.005556427307128907\n",
      "tensor(0.1986, device='cuda:0')\n",
      "Accuracy for fold 2: 19 %\n",
      "--------------------------------\n",
      "=====EPOCH : 3=====\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 104/104 [03:59<00:00,  2.30s/it]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.13482689281702043\n",
      "tensor(0.7709, device='cuda:0')\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 0/104 [00:00<?, ?it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.005591200151443481\n",
      "tensor(0.1984, device='cuda:0')\n",
      "Accuracy for fold 2: 19 %\n",
      "--------------------------------\n",
      "=====EPOCH : 4=====\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 104/104 [03:59<00:00,  2.30s/it]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.12395659448742867\n",
      "tensor(0.7730, device='cuda:0')\n",
      "0.004463901076316833\n",
      "tensor(0.1984, device='cuda:0')\n",
      "Accuracy for fold 2: 19 %\n",
      "--------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n",
      "--------------------------------\n",
      "Fold 0: 19.827999114990234 %\n",
      "Fold 1: 19.803998947143555 %\n",
      "Fold 2: 19.839998245239258 %\n",
      "Average: 19.823997497558594 %\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 0/104 [00:00<?, ?it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[    0     1     2 ... 24996 24998 24999] [    9    21    23 ... 24983 24988 24997]\n",
      "FOLD 3\n",
      "-----------------------------------\n",
      "=====EPOCH : 0=====\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 104/104 [04:00<00:00,  2.31s/it]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.22786675322532654\n",
      "tensor(0.7168, device='cuda:0')\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 0/104 [00:00<?, ?it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.0105294557762146\n",
      "tensor(0.1978, device='cuda:0')\n",
      "Accuracy for fold 3: 19 %\n",
      "--------------------------------\n",
      "=====EPOCH : 1=====\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 104/104 [04:00<00:00,  2.31s/it]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.14824281135082246\n",
      "tensor(0.7611, device='cuda:0')\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 0/104 [00:00<?, ?it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.007856149616241455\n",
      "tensor(0.1981, device='cuda:0')\n",
      "Accuracy for fold 3: 19 %\n",
      "--------------------------------\n",
      "=====EPOCH : 2=====\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 104/104 [03:59<00:00,  2.30s/it]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.1394372496151924\n",
      "tensor(0.7683, device='cuda:0')\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 0/104 [00:00<?, ?it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.00518294801235199\n",
      "tensor(0.1981, device='cuda:0')\n",
      "Accuracy for fold 3: 19 %\n",
      "--------------------------------\n",
      "=====EPOCH : 3=====\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 104/104 [04:00<00:00,  2.31s/it]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.11171350844144821\n",
      "tensor(0.7773, device='cuda:0')\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 0/104 [00:00<?, ?it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.005179627480506897\n",
      "tensor(0.1980, device='cuda:0')\n",
      "Accuracy for fold 3: 19 %\n",
      "--------------------------------\n",
      "=====EPOCH : 4=====\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 104/104 [04:00<00:00,  2.31s/it]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.1446920319378376\n",
      "tensor(0.7678, device='cuda:0')\n",
      "0.00638659945487976\n",
      "tensor(0.1982, device='cuda:0')\n",
      "Accuracy for fold 3: 19 %\n",
      "--------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n",
      "--------------------------------\n",
      "Fold 0: 19.827999114990234 %\n",
      "Fold 1: 19.803998947143555 %\n",
      "Fold 2: 19.839998245239258 %\n",
      "Fold 3: 19.81599998474121 %\n",
      "Average: 19.821998596191406 %\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 0/104 [00:00<?, ?it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[    1     2     3 ... 24997 24998 24999] [    0     6    10 ... 24990 24992 24993]\n",
      "FOLD 4\n",
      "-----------------------------------\n",
      "=====EPOCH : 0=====\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 104/104 [03:58<00:00,  2.30s/it]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.21762645963668822\n",
      "tensor(0.7262, device='cuda:0')\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 0/104 [00:00<?, ?it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.006607501277923584\n",
      "tensor(0.1980, device='cuda:0')\n",
      "Accuracy for fold 4: 19 %\n",
      "--------------------------------\n",
      "=====EPOCH : 1=====\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 104/104 [04:02<00:00,  2.33s/it]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.12947295805215836\n",
      "tensor(0.7677, device='cuda:0')\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 0/104 [00:00<?, ?it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.005352842330932617\n",
      "tensor(0.1983, device='cuda:0')\n",
      "Accuracy for fold 4: 19 %\n",
      "--------------------------------\n",
      "=====EPOCH : 2=====\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 104/104 [04:05<00:00,  2.36s/it]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.11404778702735902\n",
      "tensor(0.7724, device='cuda:0')\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "test_files = [f'{i}.jpg' for i in range(1,12500)]\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, files, root, transform):\n",
    "        self.files = files\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(os.path.join(self.root, self.files[index]))\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((299,299)),\n",
    "    transforms.RandomCrop(255),\n",
    "    transforms.RandomHorizontalFlip(0.5),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "test_dataset = TestDataset(test_files, '/opt/ml/test1', test_transform)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, shuffle=False)\n",
    "\n",
    "model.eval()\n",
    "df = pd.read_csv('/opt/ml/skku/dog_classifier/sampleSubmission.csv')\n",
    "for i, test_batch in enumerate(test_loader):\n",
    "    inputs = test_batch\n",
    "    inputs = inputs.to(device)\n",
    "\n",
    "    outs = model(inputs)\n",
    "    preds_list = torch.functional.F.softmax(outs, dim=1)[:, 1].tolist()\n",
    "    df.iloc[i]['label'] = outs[1].cpu().numpy()\n",
    "    \n",
    "    "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[-1.7558,  1.9249]], device='cuda:0', grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for dimension 0 with size 1",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-0ba69213ffba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for dimension 0 with size 1"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "df.to_csv('sub_test2.csv',mode='w')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit"
  },
  "interpreter": {
   "hash": "98b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
