
# '21. 09. 27 NLP 강의 정리

## 1. Competition : " KLUE강의 BERT 언어모델 기반의 단일 분류를 공부하신 이후에 도전 "

### 경진대회 기간이 아닐 때

**1. 대회 개요**

관계 추출(Relation Extraction)은 문장의 단어(Entity)에 대한 속성과 관계를 예측하는 문제입니다.
관계 추출은 지식 그래프 구축을 위한 핵심 구성요소로
(1) 구조화된 검색<br></br>
(2) 감정 분석<br></br>
(3) 질문 답변하기<br></br>
(4) 요약<br></br>
과 같은 자연어처리 응용 프로그램에서 중요합니다. 비구조적인 자연어 문장에서 구조적인 triple을 추출해 정보를 요약하고,
중요한 성분을 핵심적으로 파악할 수 있습니다.

-input : Sentence, subject_entitiy, object_entitiy의 정보를 입력으로 사용 합니다.
-output : relation 30개 중 하나를 예측한 pred_label, 그리고 30개 클래스 각각에 대해 예측한 확률(prob)을 제출해야합니다.
그리고 클래스 별 확률의 순서는 아래처럼 label_list에 있는 클래스 순서와 일치시켜주시기를 부탁드립니다.

**종료**
-10/7 목요일 오후 7시에 대회 종료


## 한국어 언어 모델 학습 및 다중 과제 튜닝
**1. 인공지능의 탄생과 자연어 처리**

-피그말리온과 갈리테이아
 -인간을 대체하는 *인공물*에 대한 최초의 기록

-콜로서스 컴퓨터
 -이미테이션 게임(엘렁튜링): 기계에 지능이 있는지를 판별하고자 하는 실험
 -인간이 보기에 인간같으면 인간에 준하는 지능이 있다고 판단.

-AI의 황금기
 -ELIZA CHAT BOT
 -룰베이스 심리상담 AI
 
-인간의 자연어 처리
 -대화의 단계
 -1. 화자는 자연어 형태로 객체를 인코딩
 -2. 메세지의 전송
 -3. 청자는 자연어를 자연어로 디코딩
 
-컴퓨터의 자연어 처리
 -대화의 단계
 -1. Encoder는 벡터 형태로 자연어를 인코딩
 -2. 메세지의 전송
 -3. Decoder는 벡터형태로 자연어를 디코딩
 
**대부분의 자연어 처리 문제는 분류**

-Word2Vec
 -가장 간단한 표현은 one-hot encoding방식 -> Sparse representation 단어 벡터가 sparse해서 단어가 가지는 의미를 공간에 표현하기 어렵다.
 -한 단어의 주변 단어들을 통해, 그 단어의 의미를 파악
 -Word2vec은 주변부의 단어를 예측하는 방식으로 학습합니다.
 -벡터 연산도 가능하다.
 -Word2Vec의 장점은
  -단어간의 유사도 측정에 용이
  -단어간의 관계 파악에 용이
  -벡터 연산을 통한 추론이 가능
 -Word2Vec의 단점은
  -단어의 subword information무시
  -Out of vocabulary (OOV)에서 적용 불가능

-FastText
 -한국어는 다양한 용언형태
 -Word2Vec은 이것들을 다 독립된벡터 Fasttext는 아님
 -n-gram을 이용한다.
 




**갑자기 BatchNormalization** 출처 eehoeskrap.tistory.com/430

**Gradient Vanishing / Exploding 문제**

신경망에서 학습시 Gradient 기반의 방법들은 파라미터 값의 작은 변화가 신경망 출력에 얼마나 영향을 미칠 것인가를 기반으로 파라미터값을 학습시키게 된다.
만약 파라미터 값의 변화가 신경망의 매우 작은 변화를 미치게 될 경우 파라미터를 효과적으로 학습시킬 수 없다.
**Gradient라는 것이 결국 미분값 즉 변화량을 의미하는데 이 변화량이 매우 작아지거나(Vanishing), 커진다면(Exploding) 신경망을 효과적으로 학습시키지 못하고, Error rate가 낮아지지 않고 수렴해 버리는 문제가 발생한다.**

그래서 이러한 문제를 해결하기 위해, Sigmoid나 tanh등의 Activation function은 매우 비선형적인 방식으로 
입력값을 매우 작은 출력 값의 범위로 Squash 해버리는데, 가령 Sigmoid는 실수 범위의 수를 [0,1]로 맵핑한다.
이렇게 출력범위를 설정할 경우, 매우 넓은 입력값의 범위가 극도로 작은 범위의 결과 값으로 매핑된다.
이러한 현상은 비선형 레이어들이 여러개 있을때, 더욱 심해져 학습이 악화된다.
**첫 레이어의 입력 값에 대해 매우 큰 변화량이 있더라도 결과 값의 변화량은 극소가 되어버리는 것**이다.
그래서 이러한 문제점을 해결하기 위해 활성화 함수로 자주 쓰이는 것이 **ReLU(Rectified Linear Unit)**이다.

또 다른 방법들도 존재
-Change activation function: sigmoid to ReLU
-Careful initialization: 가중치 초기화
-Small learning rate: learning rate을 작게함

그러나 이들은 모두 간접적인 방법이고, **학습하는 과정 자체를 전체적으로 안정화**하여 학습속도를 가속시킬수 있는 것이 **배치정규화**이다.

**정규화(normalization)**
기본적으로 정규화 하는 이유는 학습을 빨리하기 위해서 or Local optimum문제에 빠지는 가능성을 줄이기 위해서다.
![image](https://user-images.githubusercontent.com/67318280/134840346-1212167a-4f5c-425d-8f99-a5c09c675fe7.png)

(좌) 정규화전 (우) 정규화 후

**Internal Covariance Shift**

배치 정규화 논문에서는 학습에서 불안정화가 일어나는 이유를 **Internal Covariance Shift**라고 주장하고 있는데, 이는 네트워크의 각 레이어나 Activation마다 입력값의 분산이 달라지는 현상이다.
-Covariate Shift : 이전 레이어의 파라미터 변화로 인하여 현재 레이어의 입력의 분포가 바뀌는 현상
-Internal Covariate Shift : 레이어를 통과할 때 마다 Covariate Shift가 일어나면서 입력의 분포가 약간씩 변화하는 현상

![image](https://user-images.githubusercontent.com/67318280/134840478-1a056c5b-8c1c-49c5-8fec-336d4679cc4d.png)
![image](https://user-images.githubusercontent.com/67318280/134840496-4a616de4-d63f-45a9-a530-91a241823edd.png)

**Whitening의 문제점**

이 현상을 막기 귀해 각 레이어의 입력의 분산을 평균 0, 표준편자 1인 입력값으로 정규화 시키는 방법을 생각해볼 수 있다.
이는 Whitening이라고 일컫는다.
기본적으로 들어오는 입력값의 특징들을 uncorrelated하게 만들어주고, 각각의 분산을 1로 만들어주는 작업이다.
이는 covariacne matrix의 계산과 inverse계산이 필요하기 때문에 계산양이 많고 whitening은 일부 파라미터들의 영향이 무시된다.



## MRC ##

오늘날 검색창에 질문을하고, 검색결과 안에서 스스로 답을 찾습니다.
검색결과에서 어떤페이지를 먼저 보면 좋을지 고민하는 겁니다.

**MRC는 기계독해 (Machine Reading Comprehension)이라 불리며 QA시스템을 정교하게 구현할 수 있는 기술의 하나로, 주어진 문서에서 사용자가 던진 질문에 대한 답을 추출하여 보여주는 기술입니다.**

**예를들어 대한민국 13대 대통령이 누구야 ?** 라는 질문을 구글에 하면 13대 대통령에 대한 정보를 내놓습니다. 

MRC(Machine Reading Comprehension)의 목표는 주어진 context와 context에 관한 질문에 답할 수 있는가입니다. KLUE-MRC에서 사용된 데이터는 위키피디아, 아크로팬, 한국경제신문입니다.

**평가 방법**

해당 Task를 평가할 때 **EM(exact match), ROUGE(character-level ROUGE-W)** 가 사용되었습니다. EM의 경우 QA model에서 가장 많이 사용하는 평가 방법으로 **실제 답변과 예측 답변이 일치하면 점수**를 얻게 됩니다. 반면 ROUGE의 경우 예측 답변과 실제 답변이 완벽하게 일치하지 않아도 점수를 얻을 수 있습니다

![image](https://user-images.githubusercontent.com/67318280/134861970-af526569-a04d-46b1-9560-23182037a59c.png)
.
